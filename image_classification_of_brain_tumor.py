# -*- coding: utf-8 -*-
"""Image classification of brain tumor.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wF-iMUudCfivrdBcfNpZOxHZWRl89gSq
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
#import the necssary libraries
import tensorflow as tf
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
# %matplotlib inline
from tensorflow.keras.preprocessing import image
from keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.metrics import categorical_crossentropy
from keras.models import Sequential, Model
from keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D
from keras.layers import Activation, Dropout, BatchNormalization, Flatten, Dense, AvgPool2D,MaxPool2D
from keras.models import Sequential, Model
from keras.optimizers import Adam
import cv2
from tensorflow.keras.applications import EfficientNetB0,MobileNetV3Large #Transfer Learning
from tensorflow.keras.callbacks import ReduceLROnPlateau, TensorBoard, ModelCheckpoint, EarlyStopping # Callbacks
from sklearn.metrics import classification_report,confusion_matrix
from warnings import filterwarnings
from tensorflow.keras.utils import to_categorical

labels = ['Normal','glioma_tumor','meningioma_tumor','pituitary_tumor']
X=[]
y=[]
image_size = 150
folderPath ='/content/drive/MyDrive/Normal brain'
for j in tqdm(os.listdir(folderPath)):
  img = cv2.imread(os.path.join(folderPath,j))
  img = cv2.resize(img,(image_size, image_size))
  X.append(img)
  y.append('Normal')

for i in labels[1:]:
   folderPath = os.path.join('/content/drive/MyDrive/tumor',i)
   for j in tqdm(os.listdir(folderPath)):
      img = cv2.imread(os.path.join(folderPath,j))
      img = cv2.resize(img,(image_size,image_size))
      X.append(img)
      y.append(i)
X= np.array(X)
y= np.array(y)

print("Shape of X:", X.shape)
print("Shape of y:", y.shape)

k=0
fig, ax = plt.subplots(1,4,figsize=(20,20))
fig.text(s='Sample Image From Each Label',size=18,y=0.62,x=0.4)
for i in labels:
    j=0
    while True :
        if y[j]==i:
            ax[k].imshow(X[j])
            ax[k].set_title(y[j])

            ax[k].axis('off')
            k+=1
            break
        j+=1

class_counts = pd.Series(y).value_counts()
plt.figure(figsize=(8, 6))
sns.barplot(x=class_counts.index, y=class_counts.values)
plt.title("Class Distribution")
plt.xlabel("Class Labels")
plt.ylabel("Counts")
plt.show()

X=X[:3098]
y=y[:3098]

print("Shape of X:", X.shape)
print("Shape of y:", y.shape)

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X ,y ,train_size=0.03, test_size=0.006,random_state=41,shuffle=True)

from sklearn.preprocessing import LabelEncoder
X_train = X_train.reshape(X_train.shape[0], -1)
X_test = X_test.reshape(X_test.shape[0], -1)

le = LabelEncoder()
y_train= le.fit_transform(y_train)
y_test=le.transform(y_test)

"""Transfer learning"""

y_new=[]
for i in y:
    y_new.append(labels.index(i))
y = y_new
y = tf.keras.utils.to_categorical(y)

X_train,X_test,y_train,y_test = train_test_split(X ,y ,train_size=0.8, test_size=0.2,random_state=41,shuffle=True)

"""Convolution Neural Network"""

model= Sequential()
model.add(Conv2D(32,(3,3),activation = 'relu',input_shape=(150,150,3)))
model.add(Conv2D(64,(3,3),activation='relu'))
model.add(MaxPooling2D(2,2))
model.add(Dropout(0.3))
model.add(Conv2D(64,(3,3),activation='relu'))
model.add(Conv2D(64,(3,3),activation='relu'))
model.add(Dropout(0.3))
model.add(MaxPooling2D(2,2))
model.add(Dropout(0.3))
model.add(Conv2D(128,(3,3),activation='relu'))
model.add(Conv2D(128,(3,3),activation='relu'))
model.add(Conv2D(128,(3,3),activation='relu'))
model.add(MaxPooling2D(2,2))
model.add(Dropout(0.3))
model.add(Conv2D(128,(3,3),activation='relu'))
model.add(Conv2D(256,(3,3),activation='relu'))
model.add(MaxPooling2D(2,2))
model.add(Dropout(0.3))
model.add(Flatten())
model.add(Dense(512,activation = 'relu'))
model.add(Dense(512,activation = 'relu'))
model.add(Dropout(0.3))
model.add(Dense(4,activation = 'softmax'))

model.summary()

model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])

model_checkpoint =  ModelCheckpoint('model.h5',monitor='val_loss',
                                                           verbose=1,
                                                           save_best_only=True,
                                                           save_weights_only=True,
                                                           mode='auto',save_freq=1)
early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=10)
history=model.fit(X_train,y_train,
                  batch_size=50,
                  epochs=12,
                  validation_data=(X_test,y_test),
                  verbose=1,
                  callbacks=[early_stopping,model_checkpoint])

model.save('brain tumor.h5')
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
epochs = range(len(acc))
fig = plt.figure(figsize=(14,7))
plt.plot(epochs,acc,'r',label="Training Accuracy")
plt.plot(epochs,val_acc,'b',label="Validation Accuracy")
plt.legend(loc='upper left')
plt.show()

loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(len(loss))
fig = plt.figure(figsize=(14,7))
plt.plot(epochs,loss,'r',label="Training loss")
plt.plot(epochs,val_loss,'b',label="Validation loss")
plt.legend(loc='upper left')
plt.show()

pred = model.predict(X_test)
pred = np.argmax(pred,axis=1)
y_test_new = np.argmax(y_test,axis=1)

print(classification_report(y_test_new,pred))

confusion_matrix(y_test_new,pred)

fig,ax=plt.subplots(1,1,figsize=(14,7))
sns.heatmap(confusion_matrix(y_test_new,pred),ax=ax,xticklabels=labels,yticklabels=labels,annot=True,fmt=".0f",alpha=0.7,linewidths=2)
fig.text(s='Heatmap of the Confusion Matrix',size=18,y=0.92,x=0.28,alpha=0.8)

"""Efficient Net"""

effnet = EfficientNetB0(weights='imagenet',include_top=False,input_shape=(150,150,3))

effnet_model = tf.keras.Sequential([
    effnet,
    GlobalAveragePooling2D(),
    Dropout(rate=0.5),
    Dense(4, activation='softmax')])

effnet_model.summary()

effnet_model.compile(loss='categorical_crossentropy',optimizer = 'Adam', metrics= ['accuracy'])

tensorboard = TensorBoard(log_dir = 'logs')
checkpoint = ModelCheckpoint("effnet.h5",monitor="val_accuracy",save_best_only=True,mode="auto",verbose=1)
reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.3, patience = 2, min_delta = 0.001,
                              mode='auto',verbose=1)

tf.__version__

history = effnet_model.fit(X_train,y_train,validation_split=0.1, epochs =12, verbose=1, batch_size=32,
                   callbacks=[tensorboard,checkpoint,reduce_lr])

effnet_model=tf.keras.models.load_model('/content/effnet.h5')

"""Using mobilenet"""

mobilenet_model = MobileNetV3Large(weights='imagenet', include_top=False, input_shape=(150,150,3))
mobinet_model = mobilenet_model.output
mobinet_model = tf.keras.layers.GlobalAveragePooling2D()(mobinet_model)
mobinet_model = tf.keras.layers.Dropout(rate=0.5)(mobinet_model)
mobinet_model = tf.keras.layers.Dense(4, activation='softmax')(mobinet_model)
mobinet_model = tf.keras.models.Model(inputs=mobilenet_model.input, outputs=mobinet_model)
mobinet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
mobinet_model.summary()

history = mobinet_model.fit(X_train,y_train,validation_split=0.1, epochs =12, verbose=1, batch_size=32,
                   callbacks=[tensorboard,checkpoint,reduce_lr])

mobinet_model=tf.keras.models.load_model('/content/mobilenet.h5')

filterwarnings('ignore')

epochs = [i for i in range(12)]
fig, ax = plt.subplots(1,2,figsize=(14,7))
train_acc = history.history['accuracy']
train_loss = history.history['loss']
val_acc = history.history['val_accuracy']
val_loss = history.history['val_loss']

fig.text(s='Epochs vs. Training and Validation Accuracy/Loss',size=18,y=1,x=0.28,alpha=0.8)

sns.despine()
ax[0].plot(epochs, train_acc, marker='o',label = 'Training Accuracy')
ax[0].plot(epochs, val_acc, marker='o',label = 'Validation Accuracy')
ax[0].legend(frameon=False)
ax[0].set_xlabel('Epochs')
ax[0].set_ylabel('Accuracy')

sns.despine()
ax[1].plot(epochs, train_loss, marker='o', label ='Training Loss')
ax[1].plot(epochs, val_loss, marker='o', label = 'Validation Loss')
ax[1].legend(frameon=False)
ax[1].set_xlabel('Epochs')
ax[1].set_ylabel('Training & Validation Loss')

fig.show()

pred = mobinet_model.predict(X_test)
pred = np.argmax(pred,axis=1)
y_test_new = np.argmax(y_test,axis=1)

print(classification_report(y_test_new,pred))

confusion_matrix(y_test_new,pred)